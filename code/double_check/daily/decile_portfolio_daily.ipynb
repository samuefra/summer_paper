{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DateRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2005-01-03', '2005-01-04', '2005-01-05', '2005-01-06',\n",
       "               '2005-01-07', '2005-01-10', '2005-01-11', '2005-01-12',\n",
       "               '2005-01-13', '2005-01-14',\n",
       "               ...\n",
       "               '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20',\n",
       "               '2019-12-23', '2019-12-24', '2019-12-26', '2019-12-27',\n",
       "               '2019-12-30', '2019-12-31'],\n",
       "              dtype='datetime64[ns]', length=3773, freq=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the daterange in daily frequency to create some dataframes (we're gonna use the marketcap dataset for this)\n",
    "returns_path = '../../../input/returns/daily.parquet'\n",
    "returns = pd.read_parquet(returns_path)\n",
    "daterange = returns.index\n",
    "daterange"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factors with 10 percentiles\n",
    "pNYSE_factors = ['pNYSE_size', 'pNYSE_value', 'pNYSE_prof', 'pNYSE_dur', 'pNYSE_valprof', \n",
    "                 'pNYSE_nissa', 'pNYSE_accruals', 'pNYSE_growth', 'pNYSE_aturnover', \n",
    "                 'pNYSE_gmargins', 'pNYSE_divp', 'pNYSE_ep', 'pNYSE_cfp', 'pNYSE_noa', \n",
    "                 'pNYSE_inv', 'pNYSE_invcap', 'pNYSE_igrowth', 'pNYSE_sgrowth', \n",
    "                 'pNYSE_lev', 'pNYSE_roaa', 'pNYSE_roea', 'pNYSE_sp', 'pNYSE_gltnoa', \n",
    "                 'pNYSE_divg', 'pNYSE_invaci', 'pNYSE_mom', 'pNYSE_indmom', 'pNYSE_valmom',\n",
    "                 'pNYSE_valmomprof', 'pNYSE_shortint', 'pNYSE_mom12', 'pNYSE_momrev',\n",
    "                 'pNYSE_lrrev', 'pNYSE_valuem', 'pNYSE_nissm', 'pNYSE_sue', 'pNYSE_roe',\n",
    "                 'pNYSE_rome', 'pNYSE_roa', 'pNYSE_strev', 'pNYSE_ivol', 'pNYSE_betaarb',\n",
    "                 'pNYSE_season', 'pNYSE_indrrev', 'pNYSE_indrrevlv', 'pNYSE_indmomrev',\n",
    "                 'pNYSE_ciss', 'pNYSE_price', 'pNYSE_age', 'pNYSE_shvol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factors with just two percentiles (1 and 10)\n",
    "pNYSE_factors_ = ['pNYSE_fscore', 'pNYSE_debtiss', 'pNYSE_repurch', 'pNYSE_exchsw', 'pNYSE_ipo']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop_ticker function: receives two parameters, percentile and df_returns. \n",
    "\n",
    "* percentile is the percentile list (p1, p2, ..., p10).\n",
    "* df_returns is the returns dataframe of any trade day.\n",
    "\n",
    "This funtion returns the percentile list with just the ticks that are in the returns dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_ticker(percentile, date, df_returns):\n",
    "    drop_tickers = []\n",
    "    for ticker in percentile:\n",
    "        if ticker not in df_returns.loc[date][df_returns.loc[date].notna()].index:\n",
    "            drop_tickers.append(ticker)\n",
    "    for ticker in drop_tickers:\n",
    "        percentile.remove(ticker)\n",
    "    return percentile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "portfolio_decile function: receives three parameters, col, df_factors and df_returns.\n",
    "\n",
    "* col is the percentile NYSE factor column (pNYSE_size, pNYSE_value, ..., pNYSE_ipo)\n",
    "* df_factors if the factors dataframe of any day.\n",
    "* df_returns is the returns dataframe of any trade day.\n",
    "\n",
    "This funtion returns all percentiles (p1, p2, ..., p10), each of them has tickers of firms whose are in this respective percentile and there is its matching column in returns dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_decile(col, date, df_factors, df_returns): \n",
    "    # taking out all firms with NA for this specified factor\n",
    "    temp = df_factors[df_factors[col].notna()]\n",
    "\n",
    "    # creating an empty list for 10 percentiles\n",
    "    p1 = []\n",
    "    p2 = [] \n",
    "    p3 = [] \n",
    "    p4 = [] \n",
    "    p5 = [] \n",
    "    p6 = [] \n",
    "    p7 = [] \n",
    "    p8 = [] \n",
    "    p9 = [] \n",
    "    p10 = [] \n",
    "\n",
    "    # filling the percentile lists with the respective tickers whose are in this percentile\n",
    "    for permno in temp.index:\n",
    "        if temp[col][permno] == 1:\n",
    "            p1.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 2:\n",
    "            p2.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 3:\n",
    "            p3.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 4:\n",
    "            p4.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 5:\n",
    "            p5.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 6:\n",
    "            p6.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 7:\n",
    "            p7.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 8:\n",
    "            p8.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 9:\n",
    "            p9.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 10:\n",
    "            p10.append(temp['TAQ_TICKER'][permno])\n",
    "\n",
    "    \"\"\"\n",
    "    Now, we need to use the drop_ticker function.\n",
    "    Thus, we'll have the percentile lists with just the tickers that are in the returns dataframe.\n",
    "    We'll use a loop to pass for all percentile lists\n",
    "    \"\"\"    \n",
    "    percentiles = [p1,p2,p3,p4,p5,p6,p7,p8,p9,p10]\n",
    "    for p in percentiles:\n",
    "        drop_ticker(p, date, df_returns)\n",
    "\n",
    "    return(p1, p2, p3, p4, p5, p6, p7, p8, p9, p10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "value_weight function: receives two parameters, percentile and df_factors.\n",
    "\n",
    "* percentile is the percentile list (p1, p2, ..., p10).\n",
    "* df_factors if the factors dataframe of any day.\n",
    "\n",
    "This funtion returns the value weight of the firms in this percentile (they are in the same sequence of the percentile list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_weight(percentile, df_factors):\n",
    "    # getting the marketcap value list\n",
    "    marketcap = list(df_factors[df_factors['TAQ_TICKER'].isin(percentile)]['MARKETCAP'].values)\n",
    "    # sum of the marketcaps of this percentile firms\n",
    "    sum_marketcap = sum(marketcap)\n",
    "    # getting the value weight\n",
    "    weight = marketcap/sum_marketcap\n",
    "    return weight"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "portfolio_formation function: receives four parameters, col, df, df_factors, df_returns.\n",
    "\n",
    "* col is the percentile NYSE factor column (pNYSE_size, pNYSE_value, ..., pNYSE_shvol).\n",
    "* df is the factor dataframe which will be filled with the value weighted portfolios.\n",
    "* df_factors if the factors dataframe of any day.\n",
    "* df_returns is the returns dataframe of any trade day.\n",
    "\n",
    "This funtion returns nothing. It just fills the df inputed with portfolio returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_formation(date, col, df, df_factors, df_returns):\n",
    "    # getting the percentile lists from portfolio_decile function\n",
    "    p1, p2, p3, p4, p5, p6, p7, p8, p9, p10 = portfolio_decile(col, date, df_factors, df_returns)\n",
    "\n",
    "    \"\"\"\n",
    "    Now, we'll fill the df (input) dataframe with percentiles portfolios.\n",
    "    Each percentile column of df will receive the value weighted portfolio of the stock returns in this specified percentile.\n",
    "    \"\"\"\n",
    "\n",
    "    df['p1'][date] = ((returns[p1].loc[date])*(value_weight(p1, df_factors))).sum(axis=0)\n",
    "    df['p2'][date] = ((returns[p2].loc[date])*(value_weight(p2, df_factors))).sum(axis=0)\n",
    "    df['p3'][date] = ((returns[p3].loc[date])*(value_weight(p3, df_factors))).sum(axis=0)\n",
    "    df['p4'][date] = ((returns[p4].loc[date])*(value_weight(p4, df_factors))).sum(axis=0)\n",
    "    df['p5'][date] = ((returns[p5].loc[date])*(value_weight(p5, df_factors))).sum(axis=0)\n",
    "    df['p6'][date] = ((returns[p6].loc[date])*(value_weight(p6, df_factors))).sum(axis=0)\n",
    "    df['p7'][date] = ((returns[p7].loc[date])*(value_weight(p7, df_factors))).sum(axis=0)\n",
    "    df['p8'][date] = ((returns[p8].loc[date])*(value_weight(p8, df_factors))).sum(axis=0)\n",
    "    df['p9'][date] = ((returns[p9].loc[date])*(value_weight(p9, df_factors))).sum(axis=0)\n",
    "    df['p10'][date] = ((returns[p10].loc[date])*(value_weight(p10, df_factors))).sum(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "portfolio_formation_ function: receives four parameters, col, df, df_factors, df_returns.\n",
    "\n",
    "* col is the percentile NYSE factor column (pNYSE_fscore, pNYSE_debtiss, pNYSE_repurch, pNYSE_exchsw, pNYSE_ipo).\n",
    "* df is the factor dataframe which will be filled with the value weighted portfolios.\n",
    "* df_factors if the factors dataframe of any day.\n",
    "* df_returns is the returns dataframe of any trade day.\n",
    "\n",
    "This funtion returns nothing. It just fills the df inputed with portfolio returns.\n",
    "\n",
    "Obs.: This function do the same thing that portfolio_formation, but it does for binary factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_formation_(date, col, df, df_factors, df_returns):\n",
    "    # getting the percentile lists from portfolio_decile function\n",
    "    p1, p2, p3, p4, p5, p6, p7, p8, p9, p10 = portfolio_decile(col, date, df_factors, df_returns)\n",
    "\n",
    "    \"\"\"\n",
    "    Now, we'll fill the df (input) dataframe with percentiles portfolios.\n",
    "    Each percentile column of df will receive the value weighted portfolio of the stock returns in this specified percentile.\n",
    "    \"\"\"\n",
    "\n",
    "    df['p1'][date] = ((df_returns[p1].loc[date])*(value_weight(p1, df_factors))).sum(axis=0)\n",
    "    df['p10'][date] = ((df_returns[p10].loc[date])*(value_weight(p10, df_factors))).sum(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_firms function: receives four parameters, col, df, df_factors, df_returns.\n",
    "\n",
    "* col is the percentile NYSE factor column (pNYSE_size, pNYSE_value, ..., pNYSE_ipo).\n",
    "* df is the factor dataframe which will be filled with the value weighted portfolios.\n",
    "* df_factors if the factors dataframe of any day.\n",
    "* df_returns is the returns dataframe of any trade day.\n",
    "\n",
    "This funtion returns nothing. It just fills the df inputed with number of firms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_firms(col, df, date, df_factors, df_returns):\n",
    "    # getting the percentile lists from portfolio_decile function\n",
    "    p1, p2, p3, p4, p5, p6, p7, p8, p9, p10 = portfolio_decile(col, date, df_factors, df_returns)\n",
    "\n",
    "    \"\"\"\n",
    "    Now, we'll fill the df (input) dataframe with number of firms by percentile.\n",
    "    Each percentile column of df will receive the number of firms in this specified percentile.\n",
    "    \"\"\"\n",
    "\n",
    "    df['p1'][date] = len(p1)\n",
    "    df['p2'][date] = len(p2)\n",
    "    df['p3'][date] = len(p3)\n",
    "    df['p4'][date] = len(p4)\n",
    "    df['p5'][date] = len(p5)\n",
    "    df['p6'][date] = len(p6)\n",
    "    df['p7'][date] = len(p7)\n",
    "    df['p8'][date] = len(p8)\n",
    "    df['p9'][date] = len(p9)\n",
    "    df['p10'][date] = len(p10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Portfolio-by-Deciles Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pNYSE_size'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pNYSE = pNYSE_factors[0]\n",
    "pNYSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'size'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor = pNYSE[6:]\n",
    "factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p10 = pd.DataFrame(index=daterange, columns=['p1','p2','p3','p4','p5','p6','p7','p8','p9','p10'])\n",
    "\n",
    "# number of firms dataframe\n",
    "n10 = pd.DataFrame(index=daterange, columns=['p1','p2','p3','p4','p5','p6','p7','p8','p9','p10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2005-01-06 00:00:00')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = daterange[3]\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20050106'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day = str(date)[:4] + str(date)[5:7] + str(date)[8:10]\n",
    "day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factors dataframe\n",
    "factors_path = f'../../../input/factors/{day}.parquet'\n",
    "factors = pd.read_parquet(factors_path)\n",
    "# dropping all firms whose doesn't have TAQ_TICKER, because that is the only variable we can connect to returns database\n",
    "factors = factors[factors['TAQ_TICKER'] != '<undefined>']\n",
    "# dropping the firms with NaN value for Market Cap\n",
    "factors = factors[factors['MARKETCAP'].notna()]\n",
    "# getting the absolute value of Market Cap\n",
    "factors['MARKETCAP'] = factors['MARKETCAP'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the portfolio returns dataframes (intradaily)\n",
    "portfolio_formation(date, pNYSE, p10, factors, returns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the number of firms dataframes (daily)\n",
    "n_firms(pNYSE, n10, date, factors, returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>p10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-06</th>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.00271</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.00067</td>\n",
       "      <td>0.000907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3773 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  p1       p2        p3        p4        p5        p6   \n",
       "2005-01-03       NaN      NaN       NaN       NaN       NaN       NaN  \\\n",
       "2005-01-04       NaN      NaN       NaN       NaN       NaN       NaN   \n",
       "2005-01-05       NaN      NaN       NaN       NaN       NaN       NaN   \n",
       "2005-01-06  0.001774  0.00271  0.002593  0.002261  0.000916  0.001457   \n",
       "2005-01-07       NaN      NaN       NaN       NaN       NaN       NaN   \n",
       "...              ...      ...       ...       ...       ...       ...   \n",
       "2019-12-24       NaN      NaN       NaN       NaN       NaN       NaN   \n",
       "2019-12-26       NaN      NaN       NaN       NaN       NaN       NaN   \n",
       "2019-12-27       NaN      NaN       NaN       NaN       NaN       NaN   \n",
       "2019-12-30       NaN      NaN       NaN       NaN       NaN       NaN   \n",
       "2019-12-31       NaN      NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "                  p7        p8       p9       p10  \n",
       "2005-01-03       NaN       NaN      NaN       NaN  \n",
       "2005-01-04       NaN       NaN      NaN       NaN  \n",
       "2005-01-05       NaN       NaN      NaN       NaN  \n",
       "2005-01-06  0.000238  0.000014 -0.00067  0.000907  \n",
       "2005-01-07       NaN       NaN      NaN       NaN  \n",
       "...              ...       ...      ...       ...  \n",
       "2019-12-24       NaN       NaN      NaN       NaN  \n",
       "2019-12-26       NaN       NaN      NaN       NaN  \n",
       "2019-12-27       NaN       NaN      NaN       NaN  \n",
       "2019-12-30       NaN       NaN      NaN       NaN  \n",
       "2019-12-31       NaN       NaN      NaN       NaN  \n",
       "\n",
       "[3773 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>p10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-06</th>\n",
       "      <td>166</td>\n",
       "      <td>167</td>\n",
       "      <td>193</td>\n",
       "      <td>200</td>\n",
       "      <td>214</td>\n",
       "      <td>241</td>\n",
       "      <td>291</td>\n",
       "      <td>334</td>\n",
       "      <td>587</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3773 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             p1   p2   p3   p4   p5   p6   p7   p8   p9   p10\n",
       "2005-01-03  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   NaN\n",
       "2005-01-04  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   NaN\n",
       "2005-01-05  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   NaN\n",
       "2005-01-06  166  167  193  200  214  241  291  334  587  1972\n",
       "2005-01-07  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   NaN\n",
       "...         ...  ...  ...  ...  ...  ...  ...  ...  ...   ...\n",
       "2019-12-24  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   NaN\n",
       "2019-12-26  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   NaN\n",
       "2019-12-27  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   NaN\n",
       "2019-12-30  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   NaN\n",
       "2019-12-31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   NaN\n",
       "\n",
       "[3773 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pNYSE in pNYSE_factors[1:2]:\n",
    "    # getting just the factor name (for the output path folder)\n",
    "    factor = pNYSE[6:]\n",
    "\n",
    "    # portfolio returns dataframe\n",
    "    p10 = pd.DataFrame(index=daterange, columns=['p1','p2','p3','p4','p5','p6','p7','p8','p9','p10'])\n",
    "\n",
    "    # number of firms dataframe\n",
    "    n10 = pd.DataFrame(index=daterange, columns=['p1','p2','p3','p4','p5','p6','p7','p8','p9','p10'])\n",
    "    for date in daterange:\n",
    "        # we need to convert in the csv's names format\n",
    "        day = str(date)[:4] + str(date)[5:7] + str(date)[8:10]\n",
    "        try:\n",
    "            # factors dataframe\n",
    "            factors_path = f'../../../input/factors/{day}.parquet'\n",
    "            factors = pd.read_parquet(factors_path)\n",
    "            # dropping all firms whose doesn't have TAQ_TICKER, because that is the only variable we can connect to returns database\n",
    "            factors = factors[factors['TAQ_TICKER'] != '<undefined>']\n",
    "            # dropping the firms with NaN value for Market Cap\n",
    "            factors = factors[factors['MARKETCAP'].notna()]\n",
    "            # getting the absolute value of Market Cap\n",
    "            factors['MARKETCAP'] = factors['MARKETCAP'].abs()\n",
    "\n",
    "            # filling the portfolio returns dataframes (intradaily)\n",
    "            portfolio_formation(date, pNYSE, p10, factors, returns) \n",
    "            \n",
    "            # filling the number of firms dataframes (daily)\n",
    "            n_firms(pNYSE, n10, date, factors, returns)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # converting portfolio returns dataframes to csv\n",
    "    output_path = f'../../../output/data/double_check/{factor}/p10.parquet'\n",
    "    p10.to_parquet(output_path)\n",
    "    \n",
    "    # converting number of firms dataframes to csv\n",
    "    output_path = f'../../../output/data/double_check/{factor}/n10_daily.parquet'\n",
    "    n10.to_parquet(output_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Portfolio Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pNYSE in pNYSE_factors_:\n",
    "    # getting just the factor name (for the output path folder)\n",
    "    factor = pNYSE[6:]\n",
    "\n",
    "    # portfolio returns dataframe\n",
    "    p10 = pd.DataFrame(index=daterange, columns=['p1','p2','p3','p4','p5','p6','p7','p8','p9','p10'])\n",
    "    \n",
    "    # number of firms dataframe\n",
    "    n10 = pd.DataFrame(index=daterange, columns=['p1','p2','p3','p4','p5','p6','p7','p8','p9','p10'])\n",
    "    for date in daterange:\n",
    "        # we need to convert in the csv's names format\n",
    "        day = str(date)[:4] + str(date)[5:7] + str(date)[8:10]\n",
    "        try:\n",
    "            # factors dataframe\n",
    "            factors_path = f'../../../input/factors/{day}.parquet'\n",
    "            factors = pd.read_parquet(factors_path)\n",
    "            # dropping all firms whose doesn't have TAQ_TICKER, because that is the only variable we can connect to returns database\n",
    "            factors = factors[factors['TAQ_TICKER'] != '<undefined>']\n",
    "            # dropping the firms with NaN value for Market Cap\n",
    "            factors = factors[factors['MARKETCAP'].notna()]\n",
    "            # getting the absolute value of Market Cap\n",
    "            factors['MARKETCAP'] = factors['MARKETCAP'].abs()\n",
    "\n",
    "            # filling the portfolio returns dataframes (intradaily)\n",
    "            portfolio_formation(date, pNYSE, p10, factors, returns) \n",
    "            \n",
    "            # filling the number of firms dataframes (daily)\n",
    "            date = pd.to_datetime(day)\n",
    "            n_firms(pNYSE, n10, date, factors, returns)\n",
    "        except:\n",
    "            pass\n",
    "    # converting portfolio returns dataframes to csv\n",
    "    output_path = f'../../../output/data/double_check/{factor}/p10.parquet'\n",
    "    p10.to_parquet(output_path)\n",
    "\n",
    "    # converting number of firms dataframes to csv\n",
    "    output_path = f'../../../output/data/double_check/{factor}/n10_daily.parquet'\n",
    "    n10.to_parquet(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
