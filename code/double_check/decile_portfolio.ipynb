{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packeges\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we're gonna create portfolios by decile for two factors, size and value from our intradaily sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the daterange in daily frequency to create some dataframes (we're gonna use the marketcap dataset for this)\n",
    "mktcap_path = '../../output/data/marketcap.csv'\n",
    "marketcap = pd.read_csv(mktcap_path, index_col=0)\n",
    "daterange = marketcap.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2005-01-03', '2005-01-04', '2005-01-05', '2005-01-06',\n",
       "               '2005-01-07', '2005-01-10', '2005-01-11', '2005-01-12',\n",
       "               '2005-01-13', '2005-01-14',\n",
       "               ...\n",
       "               '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20',\n",
       "               '2019-12-23', '2019-12-24', '2019-12-26', '2019-12-27',\n",
       "               '2019-12-30', '2019-12-31'],\n",
       "              dtype='datetime64[ns]', length=3775, freq=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datetime object\n",
    "daterange = pd.to_datetime(daterange)\n",
    "daterange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the factor column names from factors (we're gonna need this for the last loop)\n",
    "factors_path = f'../../input/factors/20050103.csv'\n",
    "factors = pd.read_csv(factors_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all factors\n",
    "pNYSE_factors = factors.columns[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pNYSE_size', 'pNYSE_value', 'pNYSE_prof', 'pNYSE_dur', 'pNYSE_valprof',\n",
       "       'pNYSE_fscore', 'pNYSE_debtiss', 'pNYSE_repurch', 'pNYSE_nissa',\n",
       "       'pNYSE_accruals', 'pNYSE_growth', 'pNYSE_aturnover', 'pNYSE_gmargins',\n",
       "       'pNYSE_divp', 'pNYSE_ep', 'pNYSE_cfp', 'pNYSE_noa', 'pNYSE_inv',\n",
       "       'pNYSE_invcap', 'pNYSE_igrowth', 'pNYSE_sgrowth', 'pNYSE_lev',\n",
       "       'pNYSE_roaa', 'pNYSE_roea', 'pNYSE_sp', 'pNYSE_gltnoa', 'pNYSE_divg',\n",
       "       'pNYSE_invaci', 'pNYSE_mom', 'pNYSE_indmom', 'pNYSE_valmom',\n",
       "       'pNYSE_valmomprof', 'pNYSE_shortint', 'pNYSE_mom12', 'pNYSE_momrev',\n",
       "       'pNYSE_lrrev', 'pNYSE_valuem', 'pNYSE_nissm', 'pNYSE_sue', 'pNYSE_roe',\n",
       "       'pNYSE_rome', 'pNYSE_roa', 'pNYSE_strev', 'pNYSE_ivol', 'pNYSE_betaarb',\n",
       "       'pNYSE_season', 'pNYSE_indrrev', 'pNYSE_indrrevlv', 'pNYSE_indmomrev',\n",
       "       'pNYSE_ciss', 'pNYSE_price', 'pNYSE_age', 'pNYSE_shvol', 'pNYSE_exchsw',\n",
       "       'pNYSE_ipo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pNYSE_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factors with just two percentiles (1 and 10)\n",
    "pNYSE_factors_ = ['pNYSE_fscore', 'pNYSE_debtiss', 'pNYSE_repurch', 'pNYSE_exchsw', 'pNYSE_ipo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the factors with just two percentiles\n",
    "pNYSE_factors = list(set(pNYSE_factors) - set(pNYSE_factors_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pNYSE_igrowth',\n",
       " 'pNYSE_season',\n",
       " 'pNYSE_divp',\n",
       " 'pNYSE_indrrev',\n",
       " 'pNYSE_divg',\n",
       " 'pNYSE_lrrev',\n",
       " 'pNYSE_strev',\n",
       " 'pNYSE_inv',\n",
       " 'pNYSE_price',\n",
       " 'pNYSE_sue',\n",
       " 'pNYSE_indmom',\n",
       " 'pNYSE_roa',\n",
       " 'pNYSE_age',\n",
       " 'pNYSE_sp',\n",
       " 'pNYSE_shortint',\n",
       " 'pNYSE_growth',\n",
       " 'pNYSE_roaa',\n",
       " 'pNYSE_lev',\n",
       " 'pNYSE_roe',\n",
       " 'pNYSE_indmomrev',\n",
       " 'pNYSE_mom',\n",
       " 'pNYSE_momrev',\n",
       " 'pNYSE_ep',\n",
       " 'pNYSE_invcap',\n",
       " 'pNYSE_gltnoa',\n",
       " 'pNYSE_gmargins',\n",
       " 'pNYSE_cfp',\n",
       " 'pNYSE_roea',\n",
       " 'pNYSE_noa',\n",
       " 'pNYSE_valmom',\n",
       " 'pNYSE_invaci',\n",
       " 'pNYSE_aturnover',\n",
       " 'pNYSE_sgrowth',\n",
       " 'pNYSE_mom12',\n",
       " 'pNYSE_indrrevlv',\n",
       " 'pNYSE_dur',\n",
       " 'pNYSE_nissa',\n",
       " 'pNYSE_value',\n",
       " 'pNYSE_valuem',\n",
       " 'pNYSE_size',\n",
       " 'pNYSE_accruals',\n",
       " 'pNYSE_nissm',\n",
       " 'pNYSE_shvol',\n",
       " 'pNYSE_betaarb',\n",
       " 'pNYSE_prof',\n",
       " 'pNYSE_valmomprof',\n",
       " 'pNYSE_ivol',\n",
       " 'pNYSE_ciss',\n",
       " 'pNYSE_valprof',\n",
       " 'pNYSE_rome']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pNYSE_factors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop_ticker function: receives two parameters, percentile and df_returns. \n",
    "\n",
    "* percentile is the percentile list (p1, p2, ..., p10).\n",
    "* df_returns is the returns dataframe of any trade day.\n",
    "\n",
    "This funtion returns the percentile list with just the ticks that are in the returns dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_ticker(percentile, df_returns):\n",
    "    drop_tickers = []\n",
    "    for ticker in percentile:\n",
    "        if ticker not in df_returns.columns:\n",
    "            drop_tickers.append(ticker)\n",
    "    for ticker in drop_tickers:\n",
    "        percentile.remove(ticker)\n",
    "    return percentile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "portfolio_decile function: receives three parameters, col, df_factors and df_returns.\n",
    "\n",
    "* col is the percentile NYSE factor column (pNYSE_size, pNYSE_value, ..., pNYSE_ipo)\n",
    "* df_factors if the factors dataframe of any day.\n",
    "* df_returns is the returns dataframe of any trade day.\n",
    "\n",
    "This funtion returns all percentiles (p1, p2, ..., p10), each of them has tickers of firms whose are in this respective percentile and there is its matching column in returns dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_decile(col, df_factors, df_returns): \n",
    "    # taking out all firms with NA for this specified factor\n",
    "    temp = df_factors[df_factors[col].notna()]   \n",
    "\n",
    "    # creating an empty list for 10 percentiles\n",
    "    p1 = []\n",
    "    p2 = [] \n",
    "    p3 = [] \n",
    "    p4 = [] \n",
    "    p5 = [] \n",
    "    p6 = [] \n",
    "    p7 = [] \n",
    "    p8 = [] \n",
    "    p9 = [] \n",
    "    p10 = [] \n",
    "\n",
    "    # filling the percentile lists with the respective tickers whose are in this percentile\n",
    "    for permno in temp.index:\n",
    "        if temp[col][permno] == 1:\n",
    "            p1.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 2:\n",
    "            p2.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 3:\n",
    "            p3.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 4:\n",
    "            p4.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 5:\n",
    "            p5.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 6:\n",
    "            p6.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 7:\n",
    "            p7.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 8:\n",
    "            p8.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 9:\n",
    "            p9.append(temp['TAQ_TICKER'][permno])\n",
    "        elif temp[col][permno] == 10:\n",
    "            p10.append(temp['TAQ_TICKER'][permno])\n",
    "\n",
    "    \"\"\"\n",
    "    Now, we need to use the drop_ticker function.\n",
    "    Thus, we'll have the percentile lists with just the tickers that are in the returns dataframe.\n",
    "    We'll use a loop to pass for all percentile lists\n",
    "    \"\"\"    \n",
    "    percentiles = [p1,p2,p3,p4,p5,p6,p7,p8,p9,p10]\n",
    "    for p in percentiles:\n",
    "        drop_ticker(p, df_returns)\n",
    "\n",
    "    return(p1, p2, p3, p4, p5, p6, p7, p8, p9, p10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "value_weight function: receives two parameters, percentile and df_factors.\n",
    "\n",
    "* percentile is the percentile list (p1, p2, ..., p10).\n",
    "* df_factors if the factors dataframe of any day.\n",
    "\n",
    "This funtion returns the value weight of the firms in this percentile (they are in the same sequence of the percentile list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_weight(percentile, df_factors):\n",
    "    # getting the marketcap value list\n",
    "    marketcap = list(df_factors[df_factors['TAQ_TICKER'].isin(percentile)]['MARKETCAP'].values)\n",
    "    # sum of the marketcaps of this percentile firms\n",
    "    sum_marketcap = sum(marketcap)\n",
    "    # getting the value weight\n",
    "    weight = marketcap/sum_marketcap\n",
    "    return weight"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "portfolio_formation function: receives four parameters, col, df, df_factors, df_returns.\n",
    "\n",
    "* col is the percentile NYSE factor column (pNYSE_size, pNYSE_value, ..., pNYSE_ipo).\n",
    "* df is the factor dataframe which will be filled with the value weighted portfolios.\n",
    "* df_factors if the factors dataframe of any day.\n",
    "* df_returns is the returns dataframe of any trade day.\n",
    "\n",
    "This funtion returns nothing. It just fills the df inputed with portfolio returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_formation(col, df, df_factors, df_returns):\n",
    "    # getting the percentile lists from portfolio_decile function\n",
    "    p1, p2, p3, p4, p5, p6, p7, p8, p9, p10 = portfolio_decile(col, df_factors, df_returns)\n",
    "\n",
    "    \"\"\"\n",
    "    Now, we'll fill the df (input) dataframe with percentiles portfolios.\n",
    "    Each percentile column of df will receive the value weighted portfolio of the stock returns in this specified percentile.\n",
    "    \"\"\"\n",
    "\n",
    "    df['p1'] = (df_returns[p1]*value_weight(p1, df_factors)).sum(axis=1)\n",
    "    df['p2'] = (df_returns[p2]*value_weight(p2, df_factors)).sum(axis=1)\n",
    "    df['p3'] = (df_returns[p3]*value_weight(p3, df_factors)).sum(axis=1)\n",
    "    df['p4'] = (df_returns[p4]*value_weight(p4, df_factors)).sum(axis=1)\n",
    "    df['p5'] = (df_returns[p5]*value_weight(p5, df_factors)).sum(axis=1)\n",
    "    df['p6'] = (df_returns[p6]*value_weight(p6, df_factors)).sum(axis=1)\n",
    "    df['p7'] = (df_returns[p7]*value_weight(p7, df_factors)).sum(axis=1)\n",
    "    df['p8'] = (df_returns[p8]*value_weight(p8, df_factors)).sum(axis=1)\n",
    "    df['p9'] = (df_returns[p9]*value_weight(p9, df_factors)).sum(axis=1)\n",
    "    df['p10'] = (df_returns[p10]*value_weight(p10, df_factors)).sum(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "portfolio_formation_ function: receives four parameters, col, df, df_factors, df_returns.\n",
    "\n",
    "* col is the percentile NYSE factor column (pNYSE_size, pNYSE_value, ..., pNYSE_ipo).\n",
    "* df is the factor dataframe which will be filled with the value weighted portfolios.\n",
    "* df_factors if the factors dataframe of any day.\n",
    "* df_returns is the returns dataframe of any trade day.\n",
    "\n",
    "This funtion returns nothing. It just fills the df inputed with portfolio returns.\n",
    "\n",
    "Obs.: This function do the same thing that portfolio_formation, but it does for binary factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_formation_(col, df, df_factors, df_returns):\n",
    "    # getting the percentile lists from portfolio_decile function\n",
    "    p1, p2, p3, p4, p5, p6, p7, p8, p9, p10 = portfolio_decile(col, df_factors, df_returns)\n",
    "\n",
    "    \"\"\"\n",
    "    Now, we'll fill the df (input) dataframe with percentiles portfolios.\n",
    "    Each percentile column of df will receive the value weighted portfolio of the stock returns in this specified percentile.\n",
    "    \"\"\"\n",
    "\n",
    "    df['p1'] = (df_returns[p1]*value_weight(p1, df_factors)).sum(axis=1)\n",
    "    df['p10'] = (df_returns[p10]*value_weight(p10, df_factors)).sum(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_firms function: receives four parameters, col, df, df_factors, df_returns.\n",
    "\n",
    "* col is the percentile NYSE factor column (pNYSE_size, pNYSE_value, ..., pNYSE_ipo).\n",
    "* df is the factor dataframe which will be filled with the value weighted portfolios.\n",
    "* df_factors if the factors dataframe of any day.\n",
    "* df_returns is the returns dataframe of any trade day.\n",
    "\n",
    "This funtion returns nothing. It just fills the df inputed with number of firms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_firms(col, df, date, df_factors, df_returns):\n",
    "    # getting the percentile lists from portfolio_decile function\n",
    "    p1, p2, p3, p4, p5, p6, p7, p8, p9, p10 = portfolio_decile(col, df_factors, df_returns)\n",
    "\n",
    "    \"\"\"\n",
    "    Now, we'll fill the df (input) dataframe with number of firms by percentile.\n",
    "    Each percentile column of df will receive the number of firms in this specified percentile.\n",
    "    \"\"\"\n",
    "\n",
    "    df['p1'][date] = len(p1)\n",
    "    df['p2'][date] = len(p2)\n",
    "    df['p3'][date] = len(p3)\n",
    "    df['p4'][date] = len(p4)\n",
    "    df['p5'][date] = len(p5)\n",
    "    df['p6'][date] = len(p6)\n",
    "    df['p7'][date] = len(p7)\n",
    "    df['p8'][date] = len(p8)\n",
    "    df['p9'][date] = len(p9)\n",
    "    df['p10'][date] = len(p10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to create a date range for the period we have\n",
    "bdates = pd.bdate_range('2005-01-01', '2019-12-31')\n",
    "bdates_ = []\n",
    "\n",
    "# we need to convert in the csv's names format\n",
    "for date in bdates:\n",
    "    day = str(date)[:4] + str(date)[5:7] + str(date)[8:10]\n",
    "    bdates_.append(day)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Portfolio-by-Deciles Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pNYSE in pNYSE_factors:\n",
    "    # getting just the factor name (for the output path folder)\n",
    "    factor = pNYSE[6:]\n",
    "    # number of firms dataframe\n",
    "    n10 = pd.DataFrame(index=daterange, columns=['p1','p2','p3','p4','p5','p6','p7','p8','p9','p10'])\n",
    "    for day in bdates_:\n",
    "        try:\n",
    "            # factors dataframe\n",
    "            factors_path = f'../../input/factors/{day}.csv'\n",
    "            factors = pd.read_csv(factors_path, index_col=0)\n",
    "            # dropping all firms whose doesn't have TAQ_TICKER, because that is the only variable we can connect to returns database\n",
    "            factors = factors[factors['TAQ_TICKER'] != '<undefined>']\n",
    "            # getting the absolute value of Market Cap\n",
    "            factors['MARKETCAP'] = factors['MARKETCAP'].abs()\n",
    "            # filling with 0 the firms with NaN value for Market Cap\n",
    "            factors['MARKETCAP'].fillna(0, inplace=True)\n",
    "            \n",
    "            # returns dataframe\n",
    "            returns_path = f'../../input/returns/{day}.csv'\n",
    "            returns = pd.read_csv(returns_path, index_col=0)\n",
    "            \n",
    "            # portfolio returns dataframe\n",
    "            p10 = pd.DataFrame(index=returns.index, columns=['p1','p2','p3','p4','p5','p6','p7','p8','p9','p10'])\n",
    "\n",
    "            # filling the portfolio returns dataframes (intradaily)\n",
    "            portfolio_formation(pNYSE, p10, factors, returns) \n",
    "            \n",
    "            # filling the number of firms dataframes (daily)\n",
    "            date = pd.to_datetime(day)\n",
    "            n_firms(pNYSE, n10, date, factors, returns)\n",
    "\n",
    "            # converting portfolio returns dataframes to csv\n",
    "            output_path = f'../../output/data/double_check/{factor}/{day}.csv'\n",
    "            p10.to_csv(output_path, sep=',', encoding='utf-8')\n",
    "        except:\n",
    "            pass\n",
    "    # converting number of firms dataframes to csv\n",
    "    output_path = f'../../output/data/double_check/{factor}/n10.csv'\n",
    "    n10.to_csv(output_path, sep=',', encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Portfolio Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pNYSE in pNYSE_factors_:\n",
    "    # getting just the factor name (for the output path folder)\n",
    "    factor = pNYSE[6:]\n",
    "    # number of firms dataframe\n",
    "    n10 = pd.DataFrame(index=daterange, columns=['p1','p2','p3','p4','p5','p6','p7','p8','p9','p10'])\n",
    "    for day in bdates_:\n",
    "        try:\n",
    "            # factors dataframe\n",
    "            factors_path = f'../../input/factors/{day}.csv'\n",
    "            factors = pd.read_csv(factors_path, index_col=0)\n",
    "            # dropping all firms whose doesn't have TAQ_TICKER, because that is the only variable we can connect to returns database\n",
    "            factors = factors[factors['TAQ_TICKER'] != '<undefined>']\n",
    "            # getting the absolute value of Market Cap\n",
    "            factors['MARKETCAP'] = factors['MARKETCAP'].abs()\n",
    "            # filling with 0 the firms with NaN value for Market Cap\n",
    "            factors['MARKETCAP'].fillna(0, inplace=True)\n",
    "            \n",
    "            # returns dataframe\n",
    "            returns_path = f'../../input/returns/{day}.csv'\n",
    "            returns = pd.read_csv(returns_path, index_col=0)\n",
    "            \n",
    "            # portfolio returns dataframe\n",
    "            p10 = pd.DataFrame(index=returns.index, columns=['p1','p2','p3','p4','p5','p6','p7','p8','p9','p10'])\n",
    "\n",
    "            # filling the portfolio returns dataframes (intradaily)\n",
    "            portfolio_formation_(pNYSE, p10, factors, returns) \n",
    "            \n",
    "            # filling the number of firms dataframes (daily)\n",
    "            date = pd.to_datetime(day)\n",
    "            n_firms(pNYSE, n10, date, factors, returns)\n",
    "\n",
    "            # converting portfolio returns dataframes to csv\n",
    "            output_path = f'../../output/data/double_check/{factor}/{day}.csv'\n",
    "            p10.to_csv(output_path, sep=',', encoding='utf-8')\n",
    "        except:\n",
    "            pass\n",
    "    # converting number of firms dataframes to csv\n",
    "    output_path = f'../../output/data/double_check/{factor}/n10.csv'\n",
    "    n10.to_csv(output_path, sep=',', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
