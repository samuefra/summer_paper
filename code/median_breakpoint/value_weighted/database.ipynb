{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database\n",
    "\n",
    "**Input**: \n",
    "* input/factors/YYYYMMDD.csv - factor location decile for all NYSE-listed stocks on one-minute frequency of the DD-MM-YYYY day.\n",
    "* input/returns/YYYYMMDD.csv - returns of all NYSE-listed stocks on one-minute frequency of the DD-MM-YYYY day.\n",
    "\n",
    "**Output**: \n",
    "* output/data/median_breakpoint/value_weighted/YYYYMMDD.csv - portfolios based on factors from NYSE-listed stocks on one-minute frequency of the DD-MM-YYYY day.\n",
    "\n",
    "The purpose of this notebook is to join two databases, one containing data on stock returns and the other containing the factor location deciles of each stock. From this merge, we will create value-weighted portfolios of factors using the median as breakpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "portfolio_position function: receives three parameters, col, df_factors and df_returns.\n",
    "\n",
    "* col is the percentile NYSE factor column (pNYSE_size, pNYSE_value, ..., pNYSE_ipo)\n",
    "* df_factors if the factors dataframe of any day.\n",
    "* df_returns is the returns dataframe of any trade day.\n",
    "\n",
    "This funtion returns long_position and short_position lists, each of them has tickers of firms whose are in this respective position and there is its matching column in returns dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_position(col, df_factors, df_returns):\n",
    "    long_position = []      # stocks whose we're gonna buy\n",
    "    short_position = []     # stocks whose we're gonna sell\n",
    "\n",
    "    # first, we need to drop the rows whose have NaN as decile location factor\n",
    "    temp = df_factors[df_factors[col].notna()]\n",
    "    \"\"\"\n",
    "    We create a loop with the criteria:\n",
    "    above the median '5' (strictly), then the portfolio assumes long position\n",
    "    below the median '5' (not strictly), then the portfolio assumes short position\n",
    "    \"\"\"\n",
    "    for permno in temp.index:\n",
    "        if temp.loc[permno][col] > 5:\n",
    "            long_position.append(temp.loc[permno]['TAQ_TICKER'])\n",
    "        else:\n",
    "            short_position.append(temp.loc[permno]['TAQ_TICKER'])\n",
    "    \"\"\"\n",
    "    now, we need create two loops for each list:\n",
    "    this program checks if the ticker inside of a list is on returns dataframe,\n",
    "    if not, we drop this ticker.\n",
    "    \"\"\"\n",
    "\n",
    "    drop_long_position = []\n",
    "    drop_short_position = []\n",
    "\n",
    "    for ticker in long_position:\n",
    "        if ticker not in df_returns.columns:\n",
    "            drop_long_position.append(ticker)\n",
    "\n",
    "    for ticker in drop_long_position:\n",
    "        long_position.remove(ticker)\n",
    "\n",
    "    for ticker in short_position:   \n",
    "        if ticker not in df_returns.columns:\n",
    "            drop_short_position.append(ticker)\n",
    "\n",
    "    for ticker in drop_short_position:\n",
    "        short_position.remove(ticker)\n",
    "\n",
    "    return(long_position, short_position)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "portfolio_formation function: receives four parameters, col, df, df_factors, df_returns.\n",
    "\n",
    "* col is the percentile NYSE factor column (pNYSE_size, pNYSE_value, ..., pNYSE_ipo).\n",
    "* df is the factor dataframe which will be filled with the value weighted portfolios.\n",
    "* df_factors if the factors dataframe of any day.\n",
    "* df_returns is the returns dataframe of any trade day.\n",
    "\n",
    "This funtion returns nothing. It just fills the df inputed with portfolio returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_formation(col, df, df_factors, df_returns):\n",
    "    # we use the portfolio_position() function to get the long_position and short_position list\n",
    "    long_position, short_position = portfolio_position(col, df_factors, df_returns)\n",
    "    \n",
    "    # the factor column name will be:\n",
    "    new_col = col[6].upper() + col[7:] + ' Factor'\n",
    "\n",
    "    \"\"\"\n",
    "    Now, we need to create a weight vector to form the value weighted portfolio\n",
    "    \"\"\"\n",
    "    # market cap of companies in long_position\n",
    "    marketcap_long_position = list(df_factors[df_factors['TAQ_TICKER'].isin(long_position)]['MARKETCAP'].values)\n",
    "\n",
    "    # market cap of companies in short_position\n",
    "    marketcap_short_position = list(df_factors[df_factors['TAQ_TICKER'].isin(short_position)]['MARKETCAP'].values)\n",
    "\n",
    "    # sum of market cap of companies in long_position\n",
    "    sum_marketcap_long_position = sum(marketcap_long_position)\n",
    "\n",
    "    # sum of market cap of companies in short_position\n",
    "    sum_marketcap_short_position = sum(marketcap_short_position)\n",
    "\n",
    "    # value weight of companies in long_position\n",
    "    weight_long_position = marketcap_long_position/sum_marketcap_long_position\n",
    "\n",
    "    # value weight of companies in short_position\n",
    "    weight_short_position = marketcap_short_position/sum_marketcap_short_position\n",
    "    \"\"\"\n",
    "    The portfolio is formed subtracting the weighted returns (value-weighted) of short_position stocks\n",
    "    from the weighted returns (value-weighted) of long_position stocks\n",
    "    \"\"\"\n",
    "    df[new_col] = (df_returns[long_position]*weight_long_position).sum(axis=1) - (df_returns[short_position]*weight_short_position).sum(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator Loop\n",
    "\n",
    "This loop will generate daily data (one .csv for each day) with all one-minute-frequency portfolio returns (one for each factor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to create a date range for the period we have data\n",
    "bdates = pd.bdate_range('2005-01-01', '2019-12-31')\n",
    "bdates_ = []\n",
    "\n",
    "# converting same way as csv names\n",
    "for date in bdates:\n",
    "    day = str(date)[:4] + str(date)[5:7] + str(date)[8:10]\n",
    "    bdates_.append(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in bdates_:\n",
    "    try:\n",
    "        # factors dataframe\n",
    "        factors_path = f'../../../input/factors/{day}.csv'\n",
    "        factors = pd.read_csv(factors_path, index_col=0)\n",
    "        # dropping all firms whose doesn't have TAQ_TICKER, because that is the only variable we can connect to returns database\n",
    "        factors = factors[factors['TAQ_TICKER'] != '<undefined>']\n",
    "        # fixing the marketcap column values (just get the absolute value)\n",
    "        factors['MARKETCAP'] = factors['MARKETCAP'].abs()\n",
    "        \n",
    "        # returns dataframe\n",
    "        returns_path = f'../../../input/returns/{day}.csv'\n",
    "        returns = pd.read_csv(returns_path, index_col=0)\n",
    "        \n",
    "        # portfolio returns dataframe\n",
    "        portfolio = pd.DataFrame(index=returns.index)\n",
    "\n",
    "        # a loop filling the portfolio returns dataframes (intradaily)\n",
    "        pNYSE_factors = factors.columns[4:]\n",
    "        for pNYSE in pNYSE_factors:\n",
    "            portfolio_formation(pNYSE, portfolio, factors, returns)\n",
    "\n",
    "        # converting portfolio returns dataframes to csv\n",
    "        output_path = f'../../../output/data/median_breakpoint/value_weighted/{day}.csv'\n",
    "        portfolio.to_csv(output_path, sep=',', encoding='utf-8')\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c63d8c7d738c2960218a10995aedf0a7f67a49a231e71037adf0440953cdb45b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
